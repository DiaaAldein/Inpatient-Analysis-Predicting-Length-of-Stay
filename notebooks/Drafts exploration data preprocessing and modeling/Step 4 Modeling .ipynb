{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "411e4b0f",
   "metadata": {},
   "source": [
    "Modeling main objectives:\n",
    "1) maintain the huge size of the data set which will be challenging when appling diffrent modeling approch\n",
    "2) appling three diffrent models and comparing there rusullts using two Evaluation Metrics\n",
    "   - we are going to use model Accuracy scare range from 0 to 1 A higher score indicates a better fit. \n",
    "   - We are going to use Mean absolute error (MAE): MAE is a measure of the average absolute difference between the predicted values and the actual values.\n",
    " \n",
    " * Compare the Model Accuracy score to MAE scores for different models. The model with the lowest MAE and the highest model score we are going to select.\n",
    " * checking the emportancy of the features for the model.\n",
    "3) Tune the algorithm selected the best model wiht highest evalutions from the above step using cross valdiation to select the best parameters for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f1bdb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_absolute_error, recall_score,precision_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import AdaBoostRegressor,AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_validate,GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3a62e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_group</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>type_of_admission</th>\n",
       "      <th>ccs_diagnosis_description</th>\n",
       "      <th>ccs_procedure_description</th>\n",
       "      <th>apr_drg_description</th>\n",
       "      <th>apr_mdc_description</th>\n",
       "      <th>apr_severity_of_illness_description</th>\n",
       "      <th>apr_risk_of_mortality</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>apr_medical_surgical_description_Surgical</th>\n",
       "      <th>emergency_department_indicator_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7.29</td>\n",
       "      <td>11.69</td>\n",
       "      <td>6.36</td>\n",
       "      <td>12.58</td>\n",
       "      <td>11.66</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7.29</td>\n",
       "      <td>11.69</td>\n",
       "      <td>6.36</td>\n",
       "      <td>12.58</td>\n",
       "      <td>11.66</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>7.29</td>\n",
       "      <td>11.69</td>\n",
       "      <td>6.36</td>\n",
       "      <td>12.58</td>\n",
       "      <td>11.66</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7.29</td>\n",
       "      <td>5.87</td>\n",
       "      <td>6.36</td>\n",
       "      <td>4.89</td>\n",
       "      <td>7.36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7.29</td>\n",
       "      <td>6.04</td>\n",
       "      <td>6.36</td>\n",
       "      <td>5.74</td>\n",
       "      <td>7.21</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698106</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7.29</td>\n",
       "      <td>8.01</td>\n",
       "      <td>6.16</td>\n",
       "      <td>5.38</td>\n",
       "      <td>6.91</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698107</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.29</td>\n",
       "      <td>4.71</td>\n",
       "      <td>7.35</td>\n",
       "      <td>4.78</td>\n",
       "      <td>5.19</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698108</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7.29</td>\n",
       "      <td>6.85</td>\n",
       "      <td>4.51</td>\n",
       "      <td>6.66</td>\n",
       "      <td>6.91</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698109</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7.29</td>\n",
       "      <td>10.68</td>\n",
       "      <td>6.20</td>\n",
       "      <td>12.65</td>\n",
       "      <td>9.68</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698110</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.21</td>\n",
       "      <td>11.69</td>\n",
       "      <td>6.36</td>\n",
       "      <td>11.93</td>\n",
       "      <td>11.66</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>698111 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age_group  length_of_stay  type_of_admission  \\\n",
       "0               3               5               7.29   \n",
       "1               1               8               7.29   \n",
       "2               2               8               7.29   \n",
       "3               3               4               7.29   \n",
       "4               3               3               7.29   \n",
       "...           ...             ...                ...   \n",
       "698106          3               3               7.29   \n",
       "698107          1               1               7.29   \n",
       "698108          4               3               7.29   \n",
       "698109          4               2               7.29   \n",
       "698110          3               2               7.21   \n",
       "\n",
       "        ccs_diagnosis_description  ccs_procedure_description  \\\n",
       "0                           11.69                       6.36   \n",
       "1                           11.69                       6.36   \n",
       "2                           11.69                       6.36   \n",
       "3                            5.87                       6.36   \n",
       "4                            6.04                       6.36   \n",
       "...                           ...                        ...   \n",
       "698106                       8.01                       6.16   \n",
       "698107                       4.71                       7.35   \n",
       "698108                       6.85                       4.51   \n",
       "698109                      10.68                       6.20   \n",
       "698110                      11.69                       6.36   \n",
       "\n",
       "        apr_drg_description  apr_mdc_description  \\\n",
       "0                     12.58                11.66   \n",
       "1                     12.58                11.66   \n",
       "2                     12.58                11.66   \n",
       "3                      4.89                 7.36   \n",
       "4                      5.74                 7.21   \n",
       "...                     ...                  ...   \n",
       "698106                 5.38                 6.91   \n",
       "698107                 4.78                 5.19   \n",
       "698108                 6.66                 6.91   \n",
       "698109                12.65                 9.68   \n",
       "698110                11.93                11.66   \n",
       "\n",
       "        apr_severity_of_illness_description  apr_risk_of_mortality  gender_M  \\\n",
       "0                                         1                      1         0   \n",
       "1                                         2                      1         0   \n",
       "2                                         1                      1         1   \n",
       "3                                         1                      1         0   \n",
       "4                                         2                      2         1   \n",
       "...                                     ...                    ...       ...   \n",
       "698106                                    3                      3         0   \n",
       "698107                                    3                      3         0   \n",
       "698108                                    3                      3         1   \n",
       "698109                                    4                      4         0   \n",
       "698110                                    1                      1         1   \n",
       "\n",
       "        apr_medical_surgical_description_Surgical  \\\n",
       "0                                               0   \n",
       "1                                               0   \n",
       "2                                               0   \n",
       "3                                               0   \n",
       "4                                               0   \n",
       "...                                           ...   \n",
       "698106                                          1   \n",
       "698107                                          0   \n",
       "698108                                          0   \n",
       "698109                                          1   \n",
       "698110                                          0   \n",
       "\n",
       "        emergency_department_indicator_Y  \n",
       "0                                      1  \n",
       "1                                      1  \n",
       "2                                      1  \n",
       "3                                      1  \n",
       "4                                      1  \n",
       "...                                  ...  \n",
       "698106                                 1  \n",
       "698107                                 1  \n",
       "698108                                 1  \n",
       "698109                                 1  \n",
       "698110                                 0  \n",
       "\n",
       "[698111 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the dataset.\n",
    "df = pd.read_csv('../data/processed/processed_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f42f647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 698111 entries, 0 to 698110\n",
      "Data columns (total 12 columns):\n",
      " #   Column                                     Non-Null Count   Dtype  \n",
      "---  ------                                     --------------   -----  \n",
      " 0   age_group                                  698111 non-null  int64  \n",
      " 1   length_of_stay                             698111 non-null  int64  \n",
      " 2   type_of_admission                          698111 non-null  float64\n",
      " 3   ccs_diagnosis_description                  698111 non-null  float64\n",
      " 4   ccs_procedure_description                  698111 non-null  float64\n",
      " 5   apr_drg_description                        698111 non-null  float64\n",
      " 6   apr_mdc_description                        698111 non-null  float64\n",
      " 7   apr_severity_of_illness_description        698111 non-null  int64  \n",
      " 8   apr_risk_of_mortality                      698111 non-null  int64  \n",
      " 9   gender_M                                   698111 non-null  int64  \n",
      " 10  apr_medical_surgical_description_Surgical  698111 non-null  int64  \n",
      " 11  emergency_department_indicator_Y           698111 non-null  int64  \n",
      "dtypes: float64(5), int64(7)\n",
      "memory usage: 63.9 MB\n"
     ]
    }
   ],
   "source": [
    "# Geitting Information about the Data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36171a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_group</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>type_of_admission</th>\n",
       "      <th>ccs_diagnosis_description</th>\n",
       "      <th>ccs_procedure_description</th>\n",
       "      <th>apr_drg_description</th>\n",
       "      <th>apr_mdc_description</th>\n",
       "      <th>apr_severity_of_illness_description</th>\n",
       "      <th>apr_risk_of_mortality</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>apr_medical_surgical_description_Surgical</th>\n",
       "      <th>emergency_department_indicator_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>698111.000000</td>\n",
       "      <td>698111.000000</td>\n",
       "      <td>698111.000000</td>\n",
       "      <td>698111.000000</td>\n",
       "      <td>698111.000000</td>\n",
       "      <td>698111.000000</td>\n",
       "      <td>698111.000000</td>\n",
       "      <td>698111.000000</td>\n",
       "      <td>698111.000000</td>\n",
       "      <td>698111.000000</td>\n",
       "      <td>698111.000000</td>\n",
       "      <td>698111.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.980360</td>\n",
       "      <td>6.742923</td>\n",
       "      <td>7.193846</td>\n",
       "      <td>7.082028</td>\n",
       "      <td>7.113087</td>\n",
       "      <td>7.034424</td>\n",
       "      <td>7.127619</td>\n",
       "      <td>2.418403</td>\n",
       "      <td>2.056332</td>\n",
       "      <td>0.484483</td>\n",
       "      <td>0.274614</td>\n",
       "      <td>0.659467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.956168</td>\n",
       "      <td>5.352194</td>\n",
       "      <td>0.222143</td>\n",
       "      <td>2.063644</td>\n",
       "      <td>1.925167</td>\n",
       "      <td>2.459052</td>\n",
       "      <td>1.493436</td>\n",
       "      <td>0.906452</td>\n",
       "      <td>0.985116</td>\n",
       "      <td>0.499760</td>\n",
       "      <td>0.446320</td>\n",
       "      <td>0.473889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.760000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.880000</td>\n",
       "      <td>3.930000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.210000</td>\n",
       "      <td>5.860000</td>\n",
       "      <td>6.090000</td>\n",
       "      <td>5.360000</td>\n",
       "      <td>6.590000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.290000</td>\n",
       "      <td>6.850000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>6.660000</td>\n",
       "      <td>6.840000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.290000</td>\n",
       "      <td>7.890000</td>\n",
       "      <td>8.360000</td>\n",
       "      <td>7.970000</td>\n",
       "      <td>7.360000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>7.290000</td>\n",
       "      <td>14.090000</td>\n",
       "      <td>18.640000</td>\n",
       "      <td>19.220000</td>\n",
       "      <td>11.660000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           age_group  length_of_stay  type_of_admission  \\\n",
       "count  698111.000000   698111.000000      698111.000000   \n",
       "mean        2.980360        6.742923           7.193846   \n",
       "std         0.956168        5.352194           0.222143   \n",
       "min         1.000000        1.000000           4.760000   \n",
       "25%         2.000000        3.000000           7.210000   \n",
       "50%         3.000000        5.000000           7.290000   \n",
       "75%         4.000000        9.000000           7.290000   \n",
       "max         4.000000       20.000000           7.290000   \n",
       "\n",
       "       ccs_diagnosis_description  ccs_procedure_description  \\\n",
       "count              698111.000000              698111.000000   \n",
       "mean                    7.082028                   7.113087   \n",
       "std                     2.063644                   1.925167   \n",
       "min                     2.000000                   1.500000   \n",
       "25%                     5.860000                   6.090000   \n",
       "50%                     6.850000                   6.400000   \n",
       "75%                     7.890000                   8.360000   \n",
       "max                    14.090000                  18.640000   \n",
       "\n",
       "       apr_drg_description  apr_mdc_description  \\\n",
       "count        698111.000000        698111.000000   \n",
       "mean              7.034424             7.127619   \n",
       "std               2.459052             1.493436   \n",
       "min               1.880000             3.930000   \n",
       "25%               5.360000             6.590000   \n",
       "50%               6.660000             6.840000   \n",
       "75%               7.970000             7.360000   \n",
       "max              19.220000            11.660000   \n",
       "\n",
       "       apr_severity_of_illness_description  apr_risk_of_mortality  \\\n",
       "count                        698111.000000          698111.000000   \n",
       "mean                              2.418403               2.056332   \n",
       "std                               0.906452               0.985116   \n",
       "min                               1.000000               1.000000   \n",
       "25%                               2.000000               1.000000   \n",
       "50%                               2.000000               2.000000   \n",
       "75%                               3.000000               3.000000   \n",
       "max                               4.000000               4.000000   \n",
       "\n",
       "            gender_M  apr_medical_surgical_description_Surgical  \\\n",
       "count  698111.000000                              698111.000000   \n",
       "mean        0.484483                                   0.274614   \n",
       "std         0.499760                                   0.446320   \n",
       "min         0.000000                                   0.000000   \n",
       "25%         0.000000                                   0.000000   \n",
       "50%         0.000000                                   0.000000   \n",
       "75%         1.000000                                   1.000000   \n",
       "max         1.000000                                   1.000000   \n",
       "\n",
       "       emergency_department_indicator_Y  \n",
       "count                     698111.000000  \n",
       "mean                           0.659467  \n",
       "std                            0.473889  \n",
       "min                            0.000000  \n",
       "25%                            0.000000  \n",
       "50%                            1.000000  \n",
       "75%                            1.000000  \n",
       "max                            1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistical description for numerical features\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9601d6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for duplication in data \n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b599ef",
   "metadata": {},
   "source": [
    "## 1) Maintain the huge size of the data set which will be challenging when appling diffrent modeling approch:\n",
    "##### Although the size of the data after cleaning and preprocessing decreese greatly to 143,500 entries instance and 7 features but it is still challenging to deal with it for limted pressoer laptob so we are going take small sample to run the models more efficently while maintaing the same characteristics of the data by usin straitify method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7385b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divede the data fram to x = features & y = target\n",
    "x = df.drop(\"length_of_stay\", axis = 1)\n",
    "y = df[\"length_of_stay\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b12a9a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking sample of the data using stratify to maintain data characteristics\n",
    "main_x,sample_x,main_y,sample_y = train_test_split(x,y,test_size=0.03,random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "835eb9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20944"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc91bb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will split sample data to train and test sets \n",
    "x_train,x_test,y_train,y_test = train_test_split(sample_x,sample_y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "804e95fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Stander Scaler for x_train, x_test\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0988d5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying three different models to compare between them\n",
    "models = {\"lr\": LinearRegression(),\n",
    "          \"knn\": KNeighborsRegressor(),\n",
    "          \"rf\": RandomForestRegressor(),\n",
    "        \"Adboost\": AdaBoostRegressor()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f529050b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------  lr  -------------\n",
      "Train Acurracy Score 0.29 Test Acurracy Score 0.28\n",
      "Train MAE Score:  3.445978394939736 Test MAE Score:  3.48\n",
      "************************************************************\n",
      "-----------  knn  -------------\n",
      "Train Acurracy Score 0.46 Test Acurracy Score 0.18\n",
      "Train MAE Score:  2.9624283765347887 Test MAE Score:  3.67\n",
      "************************************************************\n",
      "-----------  rf  -------------\n",
      "Train Acurracy Score 0.88 Test Acurracy Score 0.22\n",
      "Train MAE Score:  1.3780031406444095 Test MAE Score:  3.59\n",
      "************************************************************\n",
      "-----------  Adboost  -------------\n",
      "Train Acurracy Score 0.23 Test Acurracy Score 0.22\n",
      "Train MAE Score:  3.8351642910145674 Test MAE Score:  3.87\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "# running the three different models and check the result using for loop\n",
    "for name,model in models.items():\n",
    "    print(\"----------- \", name, \" -------------\")\n",
    "    model.fit(x_train_scaled,y_train)\n",
    "    y_train_pred = model.predict(x_train_scaled)\n",
    "    y_test_pred = model.predict(x_test_scaled)\n",
    "    print(\"Train Acurracy Score\", round(model.score(x_train_scaled,y_train),2),\"Test Acurracy Score\", round(model.score(x_test_scaled,y_test),2))\n",
    "    print(\"Train MAE Score: \", mean_absolute_error(y_train_pred,y_train),\"Test MAE Score: \", round(mean_absolute_error(y_test_pred,y_test),2))\n",
    "    print(\"*\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255bdf25",
   "metadata": {},
   "source": [
    "##### checking the emportancy of the features for the random forest model. by making data frame for features importancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0b8284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = list(model.feature_importances_)\n",
    "col_name = list(x_train.columns)\n",
    "feat_imp_df = pd.DataFrame({\"col_name\":col_name,\"feat_imp\":feat_imp})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae416135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_name</th>\n",
       "      <th>feat_imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age_group</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gender_M</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>emergency_department_indicator_Y</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>type_of_admission</td>\n",
       "      <td>0.006836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>apr_mdc_description</td>\n",
       "      <td>0.029507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>apr_medical_surgical_description_Surgical</td>\n",
       "      <td>0.034156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>apr_risk_of_mortality</td>\n",
       "      <td>0.059769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ccs_procedure_description</td>\n",
       "      <td>0.096865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ccs_diagnosis_description</td>\n",
       "      <td>0.099474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apr_drg_description</td>\n",
       "      <td>0.256272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>apr_severity_of_illness_description</td>\n",
       "      <td>0.417120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     col_name  feat_imp\n",
       "0                                   age_group  0.000000\n",
       "8                                    gender_M  0.000000\n",
       "10           emergency_department_indicator_Y  0.000000\n",
       "1                           type_of_admission  0.006836\n",
       "5                         apr_mdc_description  0.029507\n",
       "9   apr_medical_surgical_description_Surgical  0.034156\n",
       "7                       apr_risk_of_mortality  0.059769\n",
       "3                   ccs_procedure_description  0.096865\n",
       "2                   ccs_diagnosis_description  0.099474\n",
       "4                         apr_drg_description  0.256272\n",
       "6         apr_severity_of_illness_description  0.417120"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp_df[['col_name','feat_imp']].sort_values(by='feat_imp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d664f6e8",
   "metadata": {},
   "source": [
    "Dropping the apr_medical_surgical_description_Surgical as it is show least importancy and check the model for any improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5793b951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping apr_medical_surgical_description_Surgical from both x_train & x_test\n",
    "x_train.drop(['apr_medical_surgical_description_Surgical'],axis=1,inplace=True)\n",
    "x_test.drop(['apr_medical_surgical_description_Surgical'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0eb16a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Stander Scaler for x_train, x_test\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9154244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying three different models to compare between them\n",
    "models = {\"lr\": LinearRegression(),\n",
    "          \"knn\": KNeighborsRegressor(),\n",
    "          \"rf\": RandomForestRegressor(),\n",
    "         \"Adboost\": AdaBoostRegressor()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9379aac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------  lr  -------------\n",
      "Train Acurracy Score 0.29 Test Acurracy Score 0.28\n",
      "Train MAE Score:  3.4508678469205063 Test MAE Score:  3.48\n",
      "************************************************************\n",
      "-----------  knn  -------------\n",
      "Train Acurracy Score 0.45 Test Acurracy Score 0.17\n",
      "Train MAE Score:  2.9948567530695773 Test MAE Score:  3.67\n",
      "************************************************************\n",
      "-----------  rf  -------------\n",
      "Train Acurracy Score 0.88 Test Acurracy Score 0.22\n",
      "Train MAE Score:  1.3800275322657485 Test MAE Score:  3.59\n",
      "************************************************************\n",
      "-----------  Adboost  -------------\n",
      "Train Acurracy Score 0.22 Test Acurracy Score 0.2\n",
      "Train MAE Score:  3.9007970483995207 Test MAE Score:  3.96\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "# running the three different models and check the result using for loop\n",
    "for name,model in models.items():\n",
    "    print(\"----------- \", name, \" -------------\")\n",
    "    model.fit(x_train_scaled,y_train)\n",
    "    y_train_pred = model.predict(x_train_scaled)\n",
    "    y_test_pred = model.predict(x_test_scaled)\n",
    "    print(\"Train Acurracy Score\", round(model.score(x_train_scaled,y_train),2),\"Test Acurracy Score\", round(model.score(x_test_scaled,y_test),2))\n",
    "    print(\"Train MAE Score: \", mean_absolute_error(y_train_pred,y_train),\"Test MAE Score: \", round(mean_absolute_error(y_test_pred,y_test),2))\n",
    "    print(\"*\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cf31b4",
   "metadata": {},
   "source": [
    "* The models show No significant imporvement imporvement "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a1b652",
   "metadata": {},
   "source": [
    "#### We are going to use polynomial Features with diffrent degree and check if there are any improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "350703d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------  2  -------------\n",
      "-----------  lr  -------------\n",
      "Train Acurracy Score 0.31 Test Acurracy Score 0.29\n",
      "Train MAE Score:  3.38 Test MAE Score:  3.44\n",
      "************************************************************\n",
      "-----------  knn  -------------\n",
      "Train Acurracy Score 0.46 Test Acurracy Score 0.18\n",
      "Train MAE Score:  2.96 Test MAE Score:  3.67\n",
      "************************************************************\n",
      "-----------  rf  -------------\n",
      "Train Acurracy Score 0.88 Test Acurracy Score 0.23\n",
      "Train MAE Score:  1.38 Test MAE Score:  3.58\n",
      "************************************************************\n",
      "-----------  Adboost  -------------\n",
      "Train Acurracy Score 0.25 Test Acurracy Score 0.23\n",
      "Train MAE Score:  3.78 Test MAE Score:  3.83\n",
      "************************************************************\n",
      "-----------  3  -------------\n",
      "-----------  lr  -------------\n",
      "Train Acurracy Score 0.33 Test Acurracy Score 0.29\n",
      "Train MAE Score:  3.32 Test MAE Score:  3.43\n",
      "************************************************************\n",
      "-----------  knn  -------------\n",
      "Train Acurracy Score 0.46 Test Acurracy Score 0.18\n",
      "Train MAE Score:  2.95 Test MAE Score:  3.66\n",
      "************************************************************\n",
      "-----------  rf  -------------\n",
      "Train Acurracy Score 0.88 Test Acurracy Score 0.24\n",
      "Train MAE Score:  1.38 Test MAE Score:  3.57\n",
      "************************************************************\n",
      "-----------  Adboost  -------------\n",
      "Train Acurracy Score 0.23 Test Acurracy Score 0.21\n",
      "Train MAE Score:  3.86 Test MAE Score:  3.91\n",
      "************************************************************\n",
      "-----------  4  -------------\n",
      "-----------  lr  -------------\n",
      "Train Acurracy Score 0.36 Test Acurracy Score 0.22\n",
      "Train MAE Score:  3.24 Test MAE Score:  3.54\n",
      "************************************************************\n",
      "-----------  knn  -------------\n",
      "Train Acurracy Score 0.46 Test Acurracy Score 0.17\n",
      "Train MAE Score:  2.95 Test MAE Score:  3.68\n",
      "************************************************************\n",
      "-----------  rf  -------------\n",
      "Train Acurracy Score 0.88 Test Acurracy Score 0.24\n",
      "Train MAE Score:  1.38 Test MAE Score:  3.58\n",
      "************************************************************\n",
      "-----------  Adboost  -------------\n",
      "Train Acurracy Score 0.22 Test Acurracy Score 0.21\n",
      "Train MAE Score:  3.9 Test MAE Score:  3.95\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "for i in [2,3,4]:\n",
    "    print(\"----------- \", i, \" -------------\")\n",
    "    poly2 = PolynomialFeatures(degree=i)\n",
    "    x_train_poly = poly2.fit_transform(x_train)\n",
    "    x_test_poly = poly2.transform(x_test)\n",
    "    for name,model in models.items():\n",
    "        print(\"----------- \", name, \" -------------\")\n",
    "        model.fit(x_train_poly,y_train)\n",
    "        y_train_pred = model.predict(x_train_poly)\n",
    "        y_test_pred = model.predict(x_test_poly)\n",
    "        print(\"Train Acurracy Score\", round(model.score(x_train_poly,y_train),2), \"Test Acurracy Score\", round(model.score(x_test_poly,y_test),2))\n",
    "        print(\"Train MAE Score: \", round(mean_absolute_error(y_train_pred,y_train),2),\"Test MAE Score: \", round(mean_absolute_error(y_test_pred,y_test),2))\n",
    "        print(\"*\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756761b5",
   "metadata": {},
   "source": [
    "### Using Princeple Component Analasis after polynomial with different componant numper and check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5efa6921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using n_componests 2,5,8,10 and checking the results.\n",
    "pca=PCA(n_components=5)\n",
    "x_train_pca10 =pca.fit_transform(x_train)\n",
    "x_test_new_pca10 =pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f520eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------  Poly degree:  2  -------------\n",
      "-----------  PCA No. 2  -------------\n",
      "-----------  lr  -------------\n",
      "Train Acurracy Score 0.2 Test Acurracy Score 0.18\n",
      "Train MAE Score:  3.7 Test MAE Score:  3.74\n",
      "************************************************************\n",
      "-----------  knn  -------------\n",
      "Train Acurracy Score 0.39 Test Acurracy Score 0.08\n",
      "Train MAE Score:  3.17 Test MAE Score:  3.91\n",
      "************************************************************\n",
      "-----------  rf  -------------\n",
      "Train Acurracy Score 0.85 Test Acurracy Score 0.06\n",
      "Train MAE Score:  1.52 Test MAE Score:  3.97\n",
      "************************************************************\n",
      "-----------  Adboost  -------------\n",
      "Train Acurracy Score 0.14 Test Acurracy Score 0.13\n",
      "Train MAE Score:  4.1 Test MAE Score:  4.13\n",
      "************************************************************\n",
      "-----------  PCA No. 5  -------------\n",
      "-----------  lr  -------------\n",
      "Train Acurracy Score 0.2 Test Acurracy Score 0.18\n",
      "Train MAE Score:  3.7 Test MAE Score:  3.74\n",
      "************************************************************\n",
      "-----------  knn  -------------\n",
      "Train Acurracy Score 0.39 Test Acurracy Score 0.08\n",
      "Train MAE Score:  3.17 Test MAE Score:  3.91\n",
      "************************************************************\n",
      "-----------  rf  -------------\n",
      "Train Acurracy Score 0.85 Test Acurracy Score 0.06\n",
      "Train MAE Score:  1.53 Test MAE Score:  3.97\n",
      "************************************************************\n",
      "-----------  Adboost  -------------\n",
      "Train Acurracy Score 0.17 Test Acurracy Score 0.16\n",
      "Train MAE Score:  3.97 Test MAE Score:  3.99\n",
      "************************************************************\n",
      "-----------  PCA No. 8  -------------\n",
      "-----------  lr  -------------\n",
      "Train Acurracy Score 0.2 Test Acurracy Score 0.18\n",
      "Train MAE Score:  3.7 Test MAE Score:  3.74\n",
      "************************************************************\n",
      "-----------  knn  -------------\n",
      "Train Acurracy Score 0.39 Test Acurracy Score 0.08\n",
      "Train MAE Score:  3.17 Test MAE Score:  3.91\n",
      "************************************************************\n",
      "-----------  rf  -------------\n",
      "Train Acurracy Score 0.85 Test Acurracy Score 0.06\n",
      "Train MAE Score:  1.52 Test MAE Score:  3.98\n",
      "************************************************************\n",
      "-----------  Adboost  -------------\n",
      "Train Acurracy Score 0.18 Test Acurracy Score 0.16\n",
      "Train MAE Score:  3.89 Test MAE Score:  3.94\n",
      "************************************************************\n",
      "-----------  PCA No. 10  -------------\n",
      "-----------  lr  -------------\n",
      "Train Acurracy Score 0.2 Test Acurracy Score 0.18\n",
      "Train MAE Score:  3.7 Test MAE Score:  3.74\n",
      "************************************************************\n",
      "-----------  knn  -------------\n",
      "Train Acurracy Score 0.39 Test Acurracy Score 0.08\n",
      "Train MAE Score:  3.17 Test MAE Score:  3.91\n",
      "************************************************************\n",
      "-----------  rf  -------------\n",
      "Train Acurracy Score 0.85 Test Acurracy Score 0.06\n",
      "Train MAE Score:  1.52 Test MAE Score:  3.98\n",
      "************************************************************\n",
      "-----------  Adboost  -------------\n",
      "Train Acurracy Score 0.14 Test Acurracy Score 0.13\n",
      "Train MAE Score:  4.11 Test MAE Score:  4.14\n",
      "************************************************************\n",
      "-----------  Poly degree:  3  -------------\n",
      "-----------  PCA No. 2  -------------\n",
      "-----------  lr  -------------\n",
      "Train Acurracy Score 0.2 Test Acurracy Score 0.18\n",
      "Train MAE Score:  3.7 Test MAE Score:  3.74\n",
      "************************************************************\n",
      "-----------  knn  -------------\n",
      "Train Acurracy Score 0.39 Test Acurracy Score 0.08\n",
      "Train MAE Score:  3.17 Test MAE Score:  3.91\n",
      "************************************************************\n",
      "-----------  rf  -------------\n",
      "Train Acurracy Score 0.85 Test Acurracy Score 0.06\n",
      "Train MAE Score:  1.52 Test MAE Score:  3.97\n",
      "************************************************************\n",
      "-----------  Adboost  -------------\n",
      "Train Acurracy Score 0.15 Test Acurracy Score 0.14\n",
      "Train MAE Score:  4.07 Test MAE Score:  4.09\n",
      "************************************************************\n",
      "-----------  PCA No. 5  -------------\n",
      "-----------  lr  -------------\n",
      "Train Acurracy Score 0.2 Test Acurracy Score 0.18\n",
      "Train MAE Score:  3.7 Test MAE Score:  3.74\n",
      "************************************************************\n",
      "-----------  knn  -------------\n",
      "Train Acurracy Score 0.39 Test Acurracy Score 0.08\n",
      "Train MAE Score:  3.17 Test MAE Score:  3.91\n",
      "************************************************************\n",
      "-----------  rf  -------------\n",
      "Train Acurracy Score 0.85 Test Acurracy Score 0.06\n",
      "Train MAE Score:  1.53 Test MAE Score:  3.97\n",
      "************************************************************\n",
      "-----------  Adboost  -------------\n",
      "Train Acurracy Score 0.18 Test Acurracy Score 0.16\n",
      "Train MAE Score:  3.89 Test MAE Score:  3.94\n",
      "************************************************************\n",
      "-----------  PCA No. 8  -------------\n",
      "-----------  lr  -------------\n",
      "Train Acurracy Score 0.2 Test Acurracy Score 0.18\n",
      "Train MAE Score:  3.7 Test MAE Score:  3.74\n",
      "************************************************************\n",
      "-----------  knn  -------------\n",
      "Train Acurracy Score 0.39 Test Acurracy Score 0.08\n",
      "Train MAE Score:  3.17 Test MAE Score:  3.91\n",
      "************************************************************\n",
      "-----------  rf  -------------\n",
      "Train Acurracy Score 0.85 Test Acurracy Score 0.05\n",
      "Train MAE Score:  1.52 Test MAE Score:  3.98\n",
      "************************************************************\n",
      "-----------  Adboost  -------------\n",
      "Train Acurracy Score 0.15 Test Acurracy Score 0.13\n",
      "Train MAE Score:  4.09 Test MAE Score:  4.12\n",
      "************************************************************\n",
      "-----------  PCA No. 10  -------------\n",
      "-----------  lr  -------------\n",
      "Train Acurracy Score 0.2 Test Acurracy Score 0.18\n",
      "Train MAE Score:  3.7 Test MAE Score:  3.74\n",
      "************************************************************\n",
      "-----------  knn  -------------\n",
      "Train Acurracy Score 0.39 Test Acurracy Score 0.08\n",
      "Train MAE Score:  3.17 Test MAE Score:  3.91\n",
      "************************************************************\n",
      "-----------  rf  -------------\n",
      "Train Acurracy Score 0.85 Test Acurracy Score 0.06\n",
      "Train MAE Score:  1.52 Test MAE Score:  3.97\n",
      "************************************************************\n",
      "-----------  Adboost  -------------\n",
      "Train Acurracy Score 0.15 Test Acurracy Score 0.13\n",
      "Train MAE Score:  4.08 Test MAE Score:  4.11\n",
      "************************************************************\n",
      "-----------  Poly degree:  4  -------------\n",
      "-----------  PCA No. 2  -------------\n",
      "-----------  lr  -------------\n",
      "Train Acurracy Score 0.2 Test Acurracy Score 0.18\n",
      "Train MAE Score:  3.7 Test MAE Score:  3.74\n",
      "************************************************************\n",
      "-----------  knn  -------------\n",
      "Train Acurracy Score 0.39 Test Acurracy Score 0.08\n",
      "Train MAE Score:  3.17 Test MAE Score:  3.91\n",
      "************************************************************\n",
      "-----------  rf  -------------\n",
      "Train Acurracy Score 0.85 Test Acurracy Score 0.06\n",
      "Train MAE Score:  1.52 Test MAE Score:  3.97\n",
      "************************************************************\n",
      "-----------  Adboost  -------------\n",
      "Train Acurracy Score 0.14 Test Acurracy Score 0.13\n",
      "Train MAE Score:  4.11 Test MAE Score:  4.14\n",
      "************************************************************\n",
      "-----------  PCA No. 5  -------------\n",
      "-----------  lr  -------------\n",
      "Train Acurracy Score 0.2 Test Acurracy Score 0.18\n",
      "Train MAE Score:  3.7 Test MAE Score:  3.74\n",
      "************************************************************\n",
      "-----------  knn  -------------\n",
      "Train Acurracy Score 0.39 Test Acurracy Score 0.08\n",
      "Train MAE Score:  3.17 Test MAE Score:  3.91\n",
      "************************************************************\n",
      "-----------  rf  -------------\n",
      "Train Acurracy Score 0.85 Test Acurracy Score 0.06\n",
      "Train MAE Score:  1.52 Test MAE Score:  3.96\n",
      "************************************************************\n",
      "-----------  Adboost  -------------\n",
      "Train Acurracy Score 0.18 Test Acurracy Score 0.16\n",
      "Train MAE Score:  3.92 Test MAE Score:  3.97\n",
      "************************************************************\n",
      "-----------  PCA No. 8  -------------\n",
      "-----------  lr  -------------\n",
      "Train Acurracy Score 0.2 Test Acurracy Score 0.18\n",
      "Train MAE Score:  3.7 Test MAE Score:  3.74\n",
      "************************************************************\n",
      "-----------  knn  -------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acurracy Score 0.39 Test Acurracy Score 0.08\n",
      "Train MAE Score:  3.17 Test MAE Score:  3.91\n",
      "************************************************************\n",
      "-----------  rf  -------------\n",
      "Train Acurracy Score 0.85 Test Acurracy Score 0.06\n",
      "Train MAE Score:  1.52 Test MAE Score:  3.96\n",
      "************************************************************\n",
      "-----------  Adboost  -------------\n",
      "Train Acurracy Score 0.15 Test Acurracy Score 0.13\n",
      "Train MAE Score:  4.08 Test MAE Score:  4.12\n",
      "************************************************************\n",
      "-----------  PCA No. 10  -------------\n",
      "-----------  lr  -------------\n",
      "Train Acurracy Score 0.2 Test Acurracy Score 0.18\n",
      "Train MAE Score:  3.7 Test MAE Score:  3.74\n",
      "************************************************************\n",
      "-----------  knn  -------------\n",
      "Train Acurracy Score 0.39 Test Acurracy Score 0.08\n",
      "Train MAE Score:  3.17 Test MAE Score:  3.91\n",
      "************************************************************\n",
      "-----------  rf  -------------\n",
      "Train Acurracy Score 0.85 Test Acurracy Score 0.06\n",
      "Train MAE Score:  1.53 Test MAE Score:  3.97\n",
      "************************************************************\n",
      "-----------  Adboost  -------------\n",
      "Train Acurracy Score 0.18 Test Acurracy Score 0.16\n",
      "Train MAE Score:  3.9 Test MAE Score:  3.94\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "for i in [2,3,4]:\n",
    "    print(\"----------- \", \"Poly degree: \",i, \" -------------\")\n",
    "    poly2 = PolynomialFeatures(degree=i)\n",
    "    x_train_poly = poly2.fit_transform(x_train)\n",
    "    x_test_poly = poly2.transform(x_test)\n",
    "    \n",
    "    for n in [2,5,8,10]:\n",
    "        print(\"----------- \", \"PCA No.\",n, \" -------------\")\n",
    "        pca=PCA(n_components=2)\n",
    "        x_train_pca =pca.fit_transform(x_train)\n",
    "        x_test_pca =pca.transform(x_test)\n",
    "        \n",
    "        for name,model in models.items():\n",
    "            print(\"----------- \", name, \" -------------\")\n",
    "            model.fit(x_train_pca,y_train)\n",
    "            y_train_pred = model.predict(x_train_pca)\n",
    "            y_test_pred = model.predict(x_test_pca)\n",
    "            print(\"Train Acurracy Score\", round(model.score(x_train_pca,y_train),2), \"Test Acurracy Score\", round(model.score(x_test_pca,y_test),2))\n",
    "            print(\"Train MAE Score: \", round(mean_absolute_error(y_train_pred,y_train),2),\"Test MAE Score: \", round(mean_absolute_error(y_test_pred,y_test),2))\n",
    "            print(\"*\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5980ad9",
   "metadata": {},
   "source": [
    "### As all of the models shows bad results and befor going back to preprocessing a gain I will try to deal the model as classification model with target class between 1 to 20 days as labels and check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6929c151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to change the target to numerical to string using dictionery and map it to y train & test\n",
    "str_target = {1:'1',2:'2',3:'3',4:'4',5:'5',6:'6',7:'7',8:'8',9:'9',10:'10',11:'11',12:'12',13:'13',14:'14',15:'15',16:'16',17:'17',18:'18',19:'19',20:'20'}\n",
    "y_train = y_train.map(str_target)\n",
    "y_test = y_test.map(str_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f34eefd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19     117\n",
       "18     134\n",
       "17     145\n",
       "16     189\n",
       "15     216\n",
       "13     290\n",
       "14     303\n",
       "12     357\n",
       "11     414\n",
       "10     488\n",
       "9      591\n",
       "8      721\n",
       "20     859\n",
       "7      892\n",
       "6     1054\n",
       "5     1256\n",
       "4     1471\n",
       "1     1590\n",
       "3     1759\n",
       "2     1814\n",
       "Name: length_of_stay, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e03db23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying three different classification models to compare between them\n",
    "models = {\"lg\": LogisticRegression(),\n",
    "          \"knnc\": KNeighborsClassifier(),\n",
    "          \"rfc\": RandomForestClassifier(),\n",
    "         \"Adaboost_C\": AdaBoostClassifier(),\n",
    "         \"xgbc\": xgb.XGBClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc70ab1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------  lg  -------------\n",
      "Train Acurracy Score 0.17 Test Acurracy Score 0.16\n",
      "Train Precision Score:  0.17 Test Precision Score:  0.16\n",
      "Train Recall Score:  0.17 Test Recall Score:  0.16\n",
      "************************************************************\n",
      "-----------  knnc  -------------\n",
      "Train Acurracy Score 0.36 Test Acurracy Score 0.13\n",
      "Train Precision Score:  0.36 Test Precision Score:  0.13\n",
      "Train Recall Score:  0.36 Test Recall Score:  0.13\n",
      "************************************************************\n",
      "-----------  rfc  -------------\n",
      "Train Acurracy Score 0.96 Test Acurracy Score 0.14\n",
      "Train Precision Score:  0.96 Test Precision Score:  0.14\n",
      "Train Recall Score:  0.96 Test Recall Score:  0.14\n",
      "************************************************************\n",
      "-----------  Adaboost_C  -------------\n",
      "Train Acurracy Score 0.17 Test Acurracy Score 0.15\n",
      "Train Precision Score:  0.17 Test Precision Score:  0.15\n",
      "Train Recall Score:  0.17 Test Recall Score:  0.15\n",
      "************************************************************\n",
      "-----------  xgbc  -------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19], got ['1' '10' '11' '12' '13' '14' '15' '16' '17' '18' '19' '2' '20' '3' '4'\n '5' '6' '7' '8' '9']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15068\\1647361245.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"----------- \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\" -------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0my_train_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0my_test_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\diaapython\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    573\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\diaapython\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1356\u001b[0m         ):\n\u001b[0;32m   1357\u001b[0m             raise ValueError(\n\u001b[1;32m-> 1358\u001b[1;33m                 \u001b[1;34mf\"Invalid classes inferred from unique values of `y`.  \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1359\u001b[0m                 \u001b[1;34mf\"Expected: {expected_classes}, got {self.classes_}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19], got ['1' '10' '11' '12' '13' '14' '15' '16' '17' '18' '19' '2' '20' '3' '4'\n '5' '6' '7' '8' '9']"
     ]
    }
   ],
   "source": [
    "for name,model in models.items():\n",
    "        print(\"----------- \", name, \" -------------\")\n",
    "        model.fit(x_train_scaled,y_train)\n",
    "        y_train_pred = model.predict(x_train_scaled)\n",
    "        y_test_pred = model.predict(x_test_scaled)\n",
    "        print(\"Train Acurracy Score\", round(model.score(x_train_scaled,y_train),2), \"Test Acurracy Score\", round(model.score(x_test_scaled,y_test),2))\n",
    "        print(\"Train Precision Score: \", round(precision_score(y_train,y_train_pred,average='micro'),2),\"Test Precision Score: \", round(precision_score(y_test,y_test_pred,average='micro'),2))\n",
    "        print(\"Train Recall Score: \", round(recall_score(y_train,y_train_pred,average='micro'),2),\"Test Recall Score: \", round(recall_score(y_test,y_test_pred,average='micro'),2))\n",
    "        print(\"*\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02e31548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tring Cross validation with random forest classifier\n",
    "rfc = RandomForestClassifier()\n",
    "cv = cross_validate(rfc,x_train,y_train,cv=10,return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d084f585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13287858117326057"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34369d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([2.19315076, 2.15823007, 2.16222811, 2.15523648, 2.14023948,\n",
      "       2.10935903, 2.12531281, 2.13329577, 2.16620278, 2.12431645]), 'score_time': array([0.06980038, 0.07080817, 0.07080078, 0.07280636, 0.07081223,\n",
      "       0.0698123 , 0.07180882, 0.07480001, 0.07280684, 0.07081032]), 'test_score': array([0.12482947, 0.13710778, 0.12960437, 0.13369714, 0.13301501,\n",
      "       0.12210095, 0.14802183, 0.13233288, 0.1377899 , 0.13028649]), 'train_score': array([0.96801576, 0.96786418, 0.96756101, 0.9667273 , 0.96847052,\n",
      "       0.96718205, 0.96589359, 0.96566621, 0.96657572, 0.96559042])}\n"
     ]
    }
   ],
   "source": [
    "print(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55c95b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for Random Forest model\n",
    "params = {'criterion':['gini', 'entropy'], 'n_estimators':range(20, 300)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "07f35056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'n_estimators': range(20, 300)},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the grid search model for tuning\n",
    "grid_search = GridSearchCV(estimator=rfc,\n",
    "                          param_grid=params,\n",
    "                          scoring=\"accuracy\",\n",
    "                          n_jobs=-1)\n",
    "\n",
    "grid_search.fit(x_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6725699b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13635743519781718"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "297f7317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'n_estimators': 88}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d99c9bc",
   "metadata": {},
   "source": [
    "* The data is highly imbalance that could explain the bad model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47adf212",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SMOTE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5400\\1553896485.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# using random under sampler to maintain inbalance of the target class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# resampler = RandomUnderSampler(sampling_strategy='auto')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mresampler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'SMOTE' is not defined"
     ]
    }
   ],
   "source": [
    "# using random under sampler to maintain inbalance of the target class\n",
    "# resampler = RandomUnderSampler(sampling_strategy='auto')\n",
    "resampler = SMOTE(sampling_strategy='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c725339",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_resample,y_train_resample = resampler.fit_resample(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc45b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_resample.value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c43cde",
   "metadata": {},
   "source": [
    "* after dealing with inbalanced classes now we can check the results of classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe55c073",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_resample = pd.DataFrame((y_train_resample),columns=['length_of_stay'])\n",
    "y_train_resample = np.ravel(y_train_resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c4c415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Stander Scaler for x_train_resampled, x_test\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train_resample)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f96b9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,model in models.items():\n",
    "        print(\"----------- \", name, \" -------------\")\n",
    "        model.fit(x_train_scaled,y_train_resample)\n",
    "        y_train_pred = model.predict(x_train_resample)\n",
    "        y_test_pred = model.predict(x_test_scaled)\n",
    "        print(\"Train Acurracy Score\", round(model.score(x_train_scaled,y_train_resample),2), \"Test Acurracy Score\", round(model.score(x_test_scaled,y_test),2))\n",
    "        print(\"Train Precision Score: \", round(precision_score(y_train_resample,y_train_pred,average='micro'),2),\"Test Precision Score: \", round(precision_score(y_test,y_test_pred,average='micro'),2))\n",
    "        print(\"Train Recall Score: \", round(recall_score(y_train_resample,y_train_pred,average='micro'),2),\"Test Recall Score: \", round(recall_score(y_test,y_test_pred,average='micro'),2))\n",
    "        print(\"*\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb44650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_b_C = AdaBoostClassifier()\n",
    "ad_b_C.fit(x_train_scaled,y_train_resample)\n",
    "y_train_pred = model.predict(x_train_resample)\n",
    "y_test_pred = model.predict(x_test_scaled)\n",
    "print(\"Train Acurracy Score\", round(model.score(x_train_scaled,y_train_resample),2), \"Test Acurracy Score\", round(model.score(x_test_scaled,y_test),2))\n",
    "print(\"Train Precision Score: \", round(precision_score(y_train_resample,y_train_pred,average='micro'),2),\"Test Precision Score: \", round(precision_score(y_test,y_test_pred,average='micro'),2))\n",
    "print(\"Train Recall Score: \", round(recall_score(y_train_resample,y_train_pred,average='micro'),2),\"Test Recall Score: \", round(recall_score(y_test,y_test_pred,average='micro'),2))\n",
    "print(\"*\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1e1cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest shows increase the accuracy score to 81% but it is highly over fitted\n",
    "rfc = RandomForestClassifier(n_estimators=300,max_depth=20,max_leaf_nodes=20)\n",
    "rfc.fit(x_train_scaled,y_train_resample)\n",
    "y_train_pred = model.predict(x_train_resample)\n",
    "y_test_pred = model.predict(x_test_scaled)\n",
    "print(\"Train Acurracy Score\", round(model.score(x_train_scaled,y_train_resample),2), \"Test Acurracy Score\", round(model.score(x_test_scaled,y_test),2))\n",
    "print(\"Train Precision Score: \", round(precision_score(y_train_resample,y_train_pred,average='micro'),2),\"Test Precision Score: \", round(precision_score(y_test,y_test_pred,average='micro'),2))\n",
    "print(\"Train Recall Score: \", round(recall_score(y_train_resample,y_train_pred,average='micro'),2),\"Test Recall Score: \", round(recall_score(y_test,y_test_pred,average='micro'),2))\n",
    "print(\"*\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca5689a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = list(rfc.feature_importances_)\n",
    "col_name = list(x_train_resample.columns)\n",
    "feat_imp_df = pd.DataFrame({\"col_name\":col_name,\"feat_imp\":feat_imp})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cf09a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_df[['col_name','feat_imp']].sort_values(by='feat_imp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97394b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Stander Scaler for x_train_resampled, x_test\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train_resample)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8041f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest shows increase the accuracy score to 81% but it is highly over fitted\n",
    "rfc = RandomForestClassifier(n_estimators=300)\n",
    "rfc.fit(x_train_scaled,y_train_resample)\n",
    "y_train_pred = model.predict(x_train_resample)\n",
    "y_test_pred = model.predict(x_test_scaled)\n",
    "print(\"Train Acurracy Score\", round(model.score(x_train_scaled,y_train_resample),2), \"Test Acurracy Score\", round(model.score(x_test_scaled,y_test),2))\n",
    "print(\"Train Precision Score: \", round(precision_score(y_train_resample,y_train_pred,average='micro'),2),\"Test Precision Score: \", round(precision_score(y_test,y_test_pred,average='micro'),2))\n",
    "print(\"Train Recall Score: \", round(recall_score(y_train_resample,y_train_pred,average='micro'),2),\"Test Recall Score: \", round(recall_score(y_test,y_test_pred,average='micro'),2))\n",
    "print(\"*\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0af52b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_b_C = AdaBoostClassifier()\n",
    "ad_b_C.fit(x_train_scaled,y_train_resample)\n",
    "y_train_pred = model.predict(x_train_resample)\n",
    "y_test_pred = model.predict(x_test_scaled)\n",
    "print(\"Train Acurracy Score\", round(model.score(x_train_scaled,y_train_resample),2), \"Test Acurracy Score\", round(model.score(x_test_scaled,y_test),2))\n",
    "print(\"Train Precision Score: \", round(precision_score(y_train_resample,y_train_pred,average='micro'),2),\"Test Precision Score: \", round(precision_score(y_test,y_test_pred,average='micro'),2))\n",
    "print(\"Train Recall Score: \", round(recall_score(y_train_resample,y_train_pred,average='micro'),2),\"Test Recall Score: \", round(recall_score(y_test,y_test_pred,average='micro'),2))\n",
    "print(\"*\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce6f463",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc = xgb.XGBClassifier()\n",
    "xgbc.fit(x_train_scaled,y_train_resample)\n",
    "y_train_pred = model.predict(x_train_resample)\n",
    "y_test_pred = model.predict(x_test_scaled)\n",
    "print(\"Train Acurracy Score\", round(model.score(x_train_scaled,y_train_resample),2), \"Test Acurracy Score\", round(model.score(x_test_scaled,y_test),2))\n",
    "print(\"Train Precision Score: \", round(precision_score(y_train_resample,y_train_pred,average='micro'),2),\"Test Precision Score: \", round(precision_score(y_test,y_test_pred,average='micro'),2))\n",
    "print(\"Train Recall Score: \", round(recall_score(y_train_resample,y_train_pred,average='micro'),2),\"Test Recall Score: \", round(recall_score(y_test,y_test_pred,average='micro'),2))\n",
    "print(\"*\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5539ae51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d85a428",
   "metadata": {},
   "source": [
    "### The Models evaluations results above indicate that there are both under fitting and over fitting in the same time which mean we have to go back again to the preprocessing steps and try to deal with that for example by dropping outliers and also try different way of Categorical incoding like binary encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fbd3c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
