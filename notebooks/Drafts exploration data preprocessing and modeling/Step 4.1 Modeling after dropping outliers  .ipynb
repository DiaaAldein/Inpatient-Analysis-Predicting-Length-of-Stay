{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "411e4b0f",
   "metadata": {},
   "source": [
    "Modeling main objectives:\n",
    "1) maintain the huge size of the data set which will be challenging when appling diffrent modeling approch\n",
    "2) appling three diffrent models and comparing there rusullts using two Evaluation Metrics\n",
    "   - we are going to use model Accuracy scare range from 0 to 1 A higher score indicates a better fit. \n",
    "   - We are going to use Mean absolute error (MAE): MAE is a measure of the average absolute difference between the predicted values and the actual values.\n",
    " \n",
    " * Compare the Model Accuracy score to MAE scores for different models. The model with the lowest MAE and the highest model score we are going to select.\n",
    " * checking the emportancy of the features for the model.\n",
    "3) Tune the algorithm selected the best model wiht highest evalutions from the above step using cross valdiation to select the best parameters for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f1bdb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler,PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression,Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor,KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score,mean_absolute_error,precision_score,recall_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3a62e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_group</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>type_of_admission</th>\n",
       "      <th>ccs_diagnosis_description</th>\n",
       "      <th>ccs_procedure_description</th>\n",
       "      <th>apr_drg_description</th>\n",
       "      <th>apr_mdc_description</th>\n",
       "      <th>apr_severity_of_illness_description</th>\n",
       "      <th>apr_risk_of_mortality</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>apr_medical_surgical_description_Surgical</th>\n",
       "      <th>emergency_department_indicator_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8.63</td>\n",
       "      <td>16.72</td>\n",
       "      <td>7.57</td>\n",
       "      <td>19.22</td>\n",
       "      <td>18.55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8.63</td>\n",
       "      <td>16.72</td>\n",
       "      <td>7.57</td>\n",
       "      <td>19.22</td>\n",
       "      <td>18.55</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>8.63</td>\n",
       "      <td>16.72</td>\n",
       "      <td>7.57</td>\n",
       "      <td>19.22</td>\n",
       "      <td>18.55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8.63</td>\n",
       "      <td>6.22</td>\n",
       "      <td>7.57</td>\n",
       "      <td>4.97</td>\n",
       "      <td>8.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8.63</td>\n",
       "      <td>6.89</td>\n",
       "      <td>7.57</td>\n",
       "      <td>6.20</td>\n",
       "      <td>8.61</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722448</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8.63</td>\n",
       "      <td>9.32</td>\n",
       "      <td>6.79</td>\n",
       "      <td>5.76</td>\n",
       "      <td>7.81</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722449</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.63</td>\n",
       "      <td>4.97</td>\n",
       "      <td>8.38</td>\n",
       "      <td>5.04</td>\n",
       "      <td>5.84</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722450</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8.63</td>\n",
       "      <td>7.68</td>\n",
       "      <td>4.88</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7.81</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722451</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8.63</td>\n",
       "      <td>14.06</td>\n",
       "      <td>6.65</td>\n",
       "      <td>17.10</td>\n",
       "      <td>12.42</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722452</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8.68</td>\n",
       "      <td>16.72</td>\n",
       "      <td>7.57</td>\n",
       "      <td>16.55</td>\n",
       "      <td>18.55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>722453 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age_group  length_of_stay  type_of_admission  \\\n",
       "0               3               5               8.63   \n",
       "1               1               8               8.63   \n",
       "2               2               8               8.63   \n",
       "3               3               4               8.63   \n",
       "4               3               3               8.63   \n",
       "...           ...             ...                ...   \n",
       "722448          3               3               8.63   \n",
       "722449          1               1               8.63   \n",
       "722450          4               3               8.63   \n",
       "722451          4               2               8.63   \n",
       "722452          3               2               8.68   \n",
       "\n",
       "        ccs_diagnosis_description  ccs_procedure_description  \\\n",
       "0                           16.72                       7.57   \n",
       "1                           16.72                       7.57   \n",
       "2                           16.72                       7.57   \n",
       "3                            6.22                       7.57   \n",
       "4                            6.89                       7.57   \n",
       "...                           ...                        ...   \n",
       "722448                       9.32                       6.79   \n",
       "722449                       4.97                       8.38   \n",
       "722450                       7.68                       4.88   \n",
       "722451                      14.06                       6.65   \n",
       "722452                      16.72                       7.57   \n",
       "\n",
       "        apr_drg_description  apr_mdc_description  \\\n",
       "0                     19.22                18.55   \n",
       "1                     19.22                18.55   \n",
       "2                     19.22                18.55   \n",
       "3                      4.97                 8.57   \n",
       "4                      6.20                 8.61   \n",
       "...                     ...                  ...   \n",
       "722448                 5.76                 7.81   \n",
       "722449                 5.04                 5.84   \n",
       "722450                 7.40                 7.81   \n",
       "722451                17.10                12.42   \n",
       "722452                16.55                18.55   \n",
       "\n",
       "        apr_severity_of_illness_description  apr_risk_of_mortality  gender_M  \\\n",
       "0                                         1                      1         0   \n",
       "1                                         2                      1         0   \n",
       "2                                         1                      1         1   \n",
       "3                                         1                      1         0   \n",
       "4                                         2                      2         1   \n",
       "...                                     ...                    ...       ...   \n",
       "722448                                    3                      3         0   \n",
       "722449                                    3                      3         0   \n",
       "722450                                    3                      3         1   \n",
       "722451                                    4                      4         0   \n",
       "722452                                    1                      1         1   \n",
       "\n",
       "        apr_medical_surgical_description_Surgical  \\\n",
       "0                                               0   \n",
       "1                                               0   \n",
       "2                                               0   \n",
       "3                                               0   \n",
       "4                                               0   \n",
       "...                                           ...   \n",
       "722448                                          1   \n",
       "722449                                          0   \n",
       "722450                                          0   \n",
       "722451                                          1   \n",
       "722452                                          0   \n",
       "\n",
       "        emergency_department_indicator_Y  \n",
       "0                                      1  \n",
       "1                                      1  \n",
       "2                                      1  \n",
       "3                                      1  \n",
       "4                                      1  \n",
       "...                                  ...  \n",
       "722448                                 1  \n",
       "722449                                 1  \n",
       "722450                                 1  \n",
       "722451                                 1  \n",
       "722452                                 0  \n",
       "\n",
       "[722453 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the dataset.\n",
    "df = pd.read_csv('../data/processed/processed_droped_outliers_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f42f647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 722453 entries, 0 to 722452\n",
      "Data columns (total 12 columns):\n",
      " #   Column                                     Non-Null Count   Dtype  \n",
      "---  ------                                     --------------   -----  \n",
      " 0   age_group                                  722453 non-null  int64  \n",
      " 1   length_of_stay                             722453 non-null  int64  \n",
      " 2   type_of_admission                          722453 non-null  float64\n",
      " 3   ccs_diagnosis_description                  722453 non-null  float64\n",
      " 4   ccs_procedure_description                  722453 non-null  float64\n",
      " 5   apr_drg_description                        722453 non-null  float64\n",
      " 6   apr_mdc_description                        722453 non-null  float64\n",
      " 7   apr_severity_of_illness_description        722453 non-null  int64  \n",
      " 8   apr_risk_of_mortality                      722453 non-null  int64  \n",
      " 9   gender_M                                   722453 non-null  int64  \n",
      " 10  apr_medical_surgical_description_Surgical  722453 non-null  int64  \n",
      " 11  emergency_department_indicator_Y           722453 non-null  int64  \n",
      "dtypes: float64(5), int64(7)\n",
      "memory usage: 66.1 MB\n"
     ]
    }
   ],
   "source": [
    "# Geitting Information about the Data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36171a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_group</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>type_of_admission</th>\n",
       "      <th>ccs_diagnosis_description</th>\n",
       "      <th>ccs_procedure_description</th>\n",
       "      <th>apr_drg_description</th>\n",
       "      <th>apr_mdc_description</th>\n",
       "      <th>apr_severity_of_illness_description</th>\n",
       "      <th>apr_risk_of_mortality</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>apr_medical_surgical_description_Surgical</th>\n",
       "      <th>emergency_department_indicator_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>722453.000000</td>\n",
       "      <td>722453.000000</td>\n",
       "      <td>722453.000000</td>\n",
       "      <td>722453.000000</td>\n",
       "      <td>722453.000000</td>\n",
       "      <td>722453.000000</td>\n",
       "      <td>722453.000000</td>\n",
       "      <td>722453.000000</td>\n",
       "      <td>722453.000000</td>\n",
       "      <td>722453.000000</td>\n",
       "      <td>722453.000000</td>\n",
       "      <td>722453.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.981853</td>\n",
       "      <td>8.571092</td>\n",
       "      <td>8.557930</td>\n",
       "      <td>8.563032</td>\n",
       "      <td>8.565470</td>\n",
       "      <td>8.565019</td>\n",
       "      <td>8.562137</td>\n",
       "      <td>2.438311</td>\n",
       "      <td>2.072825</td>\n",
       "      <td>0.486364</td>\n",
       "      <td>0.275615</td>\n",
       "      <td>0.658912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.955242</td>\n",
       "      <td>11.142255</td>\n",
       "      <td>0.225746</td>\n",
       "      <td>3.713710</td>\n",
       "      <td>3.704387</td>\n",
       "      <td>5.175920</td>\n",
       "      <td>2.787466</td>\n",
       "      <td>0.915473</td>\n",
       "      <td>0.998609</td>\n",
       "      <td>0.499814</td>\n",
       "      <td>0.446824</td>\n",
       "      <td>0.474075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.060000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.880000</td>\n",
       "      <td>4.160000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.630000</td>\n",
       "      <td>6.480000</td>\n",
       "      <td>6.890000</td>\n",
       "      <td>5.650000</td>\n",
       "      <td>7.330000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.630000</td>\n",
       "      <td>7.760000</td>\n",
       "      <td>7.570000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>7.710000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.630000</td>\n",
       "      <td>9.470000</td>\n",
       "      <td>9.940000</td>\n",
       "      <td>9.490000</td>\n",
       "      <td>8.610000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>8.680000</td>\n",
       "      <td>26.070000</td>\n",
       "      <td>40.530000</td>\n",
       "      <td>46.140000</td>\n",
       "      <td>18.550000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           age_group  length_of_stay  type_of_admission  \\\n",
       "count  722453.000000   722453.000000      722453.000000   \n",
       "mean        2.981853        8.571092           8.557930   \n",
       "std         0.955242       11.142255           0.225746   \n",
       "min         1.000000        1.000000           5.060000   \n",
       "25%         2.000000        3.000000           8.630000   \n",
       "50%         3.000000        5.000000           8.630000   \n",
       "75%         4.000000       10.000000           8.630000   \n",
       "max         4.000000      120.000000           8.680000   \n",
       "\n",
       "       ccs_diagnosis_description  ccs_procedure_description  \\\n",
       "count              722453.000000              722453.000000   \n",
       "mean                    8.563032                   8.565470   \n",
       "std                     3.713710                   3.704387   \n",
       "min                     2.000000                   1.500000   \n",
       "25%                     6.480000                   6.890000   \n",
       "50%                     7.760000                   7.570000   \n",
       "75%                     9.470000                   9.940000   \n",
       "max                    26.070000                  40.530000   \n",
       "\n",
       "       apr_drg_description  apr_mdc_description  \\\n",
       "count        722453.000000        722453.000000   \n",
       "mean              8.565019             8.562137   \n",
       "std               5.175920             2.787466   \n",
       "min               1.880000             4.160000   \n",
       "25%               5.650000             7.330000   \n",
       "50%               7.400000             7.710000   \n",
       "75%               9.490000             8.610000   \n",
       "max              46.140000            18.550000   \n",
       "\n",
       "       apr_severity_of_illness_description  apr_risk_of_mortality  \\\n",
       "count                        722453.000000          722453.000000   \n",
       "mean                              2.438311               2.072825   \n",
       "std                               0.915473               0.998609   \n",
       "min                               1.000000               1.000000   \n",
       "25%                               2.000000               1.000000   \n",
       "50%                               2.000000               2.000000   \n",
       "75%                               3.000000               3.000000   \n",
       "max                               4.000000               4.000000   \n",
       "\n",
       "            gender_M  apr_medical_surgical_description_Surgical  \\\n",
       "count  722453.000000                              722453.000000   \n",
       "mean        0.486364                                   0.275615   \n",
       "std         0.499814                                   0.446824   \n",
       "min         0.000000                                   0.000000   \n",
       "25%         0.000000                                   0.000000   \n",
       "50%         0.000000                                   0.000000   \n",
       "75%         1.000000                                   1.000000   \n",
       "max         1.000000                                   1.000000   \n",
       "\n",
       "       emergency_department_indicator_Y  \n",
       "count                     722453.000000  \n",
       "mean                           0.658912  \n",
       "std                            0.474075  \n",
       "min                            0.000000  \n",
       "25%                            0.000000  \n",
       "50%                            1.000000  \n",
       "75%                            1.000000  \n",
       "max                            1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistical description for numerical features\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9601d6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for duplication in data \n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b599ef",
   "metadata": {},
   "source": [
    "## 1) Maintain the huge size of the data set which will be challenging when appling diffrent modeling approch:\n",
    "##### Although the size of the data after cleaning and preprocessing decreese greatly to 143,500 entries instance and 7 features but it is still challenging to deal with it for limted pressoer laptob so we are going take small sample to run the models more efficently while maintaing the same characteristics of the data by usin straitify method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7385b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divede the data fram to x = features & y = target\n",
    "x = df.drop(\"length_of_stay\", axis = 1)\n",
    "y = df[\"length_of_stay\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b12a9a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking sample of the data using stratify to maintain data characteristics\n",
    "main_x,sample_x,main_y,sample_y = train_test_split(x,y,test_size=0.03,random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "835eb9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21674"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc91bb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will split sample data to train and test sets \n",
    "x_train,x_test,y_train,y_test = train_test_split(sample_x,sample_y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "804e95fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Stander Scaler for x_train, x_test\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0988d5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying three different models to compare between them\n",
    "models = {\"lr\": LinearRegression(),\n",
    "          \"lasso\": Lasso(),\n",
    "          \"knn\": KNeighborsRegressor(),\n",
    "          \"rf\": RandomForestRegressor(),\n",
    "         \"xgbr\": xgboost.XGBRegressor()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f529050b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------  lr  -------------\n",
      "Train Acurracy Score 0.28 Test Acurracy Score 0.28\n",
      "Train MAE Score:  5.18 Test MAE Score:  5.43\n",
      "************************************************************\n",
      "-----------  lasso  -------------\n",
      "Train Acurracy Score 0.25 Test Acurracy Score 0.25\n",
      "Train MAE Score:  5.19 Test MAE Score:  5.44\n",
      "************************************************************\n",
      "-----------  knn  -------------\n",
      "Train Acurracy Score 0.45 Test Acurracy Score 0.22\n",
      "Train MAE Score:  4.43 Test MAE Score:  5.66\n",
      "************************************************************\n",
      "-----------  rf  -------------\n",
      "Train Acurracy Score 0.85 Test Acurracy Score 0.23\n",
      "Train MAE Score:  2.17 Test MAE Score:  5.67\n",
      "************************************************************\n",
      "-----------  xgbr  -------------\n",
      "Train Acurracy Score 0.65 Test Acurracy Score 0.23\n",
      "Train MAE Score:  3.76 Test MAE Score:  5.46\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "# running the three different models and check the result using for loop\n",
    "for name,model in models.items():\n",
    "    print(\"----------- \", name, \" -------------\")\n",
    "    model.fit(x_train_scaled,y_train)\n",
    "    y_train_pred = model.predict(x_train_scaled)\n",
    "    y_test_pred = model.predict(x_test_scaled)\n",
    "    print(\"Train Acurracy Score\", round(model.score(x_train_scaled,y_train),2),\"Test Acurracy Score\", round(model.score(x_test_scaled,y_test),2))\n",
    "    print(\"Train MAE Score: \", round(mean_absolute_error(y_train_pred,y_train),2),\"Test MAE Score: \", round(mean_absolute_error(y_test_pred,y_test),2))\n",
    "    print(\"*\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255bdf25",
   "metadata": {},
   "source": [
    "##### checking the emportancy of the features for the random forest model. by making data frame for features importancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0b8284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = list(model.feature_importances_)\n",
    "col_name = list(x_train.columns)\n",
    "feat_imp_df = pd.DataFrame({\"col_name\":col_name,\"feat_imp\":feat_imp})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae416135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_name</th>\n",
       "      <th>feat_imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age_group</td>\n",
       "      <td>0.040589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ccs_diagnosis_description</td>\n",
       "      <td>0.048181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>type_of_admission</td>\n",
       "      <td>0.053766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gender_M</td>\n",
       "      <td>0.055371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ccs_procedure_description</td>\n",
       "      <td>0.059190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>apr_mdc_description</td>\n",
       "      <td>0.059997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>emergency_department_indicator_Y</td>\n",
       "      <td>0.061665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>apr_risk_of_mortality</td>\n",
       "      <td>0.061797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>apr_medical_surgical_description_Surgical</td>\n",
       "      <td>0.143003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apr_drg_description</td>\n",
       "      <td>0.196195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>apr_severity_of_illness_description</td>\n",
       "      <td>0.220244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     col_name  feat_imp\n",
       "0                                   age_group  0.040589\n",
       "2                   ccs_diagnosis_description  0.048181\n",
       "1                           type_of_admission  0.053766\n",
       "8                                    gender_M  0.055371\n",
       "3                   ccs_procedure_description  0.059190\n",
       "5                         apr_mdc_description  0.059997\n",
       "10           emergency_department_indicator_Y  0.061665\n",
       "7                       apr_risk_of_mortality  0.061797\n",
       "9   apr_medical_surgical_description_Surgical  0.143003\n",
       "4                         apr_drg_description  0.196195\n",
       "6         apr_severity_of_illness_description  0.220244"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp_df[['col_name','feat_imp']].sort_values(by='feat_imp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d664f6e8",
   "metadata": {},
   "source": [
    "Dropping the apr_medical_surgical_description_Surgical as it is show least importancy and check the model for any improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5793b951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping apr_medical_surgical_description_Surgical from both x_train & x_test\n",
    "x_train.drop(['apr_medical_surgical_description_Surgical'],axis=1,inplace=True)\n",
    "x_test.drop(['apr_medical_surgical_description_Surgical'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0eb16a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Stander Scaler for x_train, x_test\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9154244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying three different models to compare between them\n",
    "models = {\"lr\": LinearRegression(),\n",
    "          \"knn\": KNeighborsRegressor(),\n",
    "          \"rf\": RandomForestRegressor()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9379aac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------  lr  -------------\n",
      "Train Acurracy Score 0.274052194464368\n",
      "Train MAE Score:  5.174737812312937\n",
      "--------------------\n",
      "Test Acurracy Score 0.27808152153251786\n",
      "Test MAE Score:  5.421234868054954\n",
      "************************************************************\n",
      "-----------  knn  -------------\n",
      "Train Acurracy Score 0.44288600789095156\n",
      "Train MAE Score:  4.467444466416189\n",
      "--------------------\n",
      "Test Acurracy Score 0.21361142276973255\n",
      "Test MAE Score:  5.69912348147009\n",
      "************************************************************\n",
      "-----------  rf  -------------\n",
      "Train Acurracy Score 0.8545094477157085\n",
      "Train MAE Score:  2.1844713095150112\n",
      "--------------------\n",
      "Test Acurracy Score 0.2288062917767627\n",
      "Test MAE Score:  5.674455501778622\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "# running the three different models and check the result using for loop\n",
    "for name,model in models.items():\n",
    "    print(\"----------- \", name, \" -------------\")\n",
    "    model.fit(x_train_scaled,y_train)\n",
    "    y_train_pred = model.predict(x_train_scaled)\n",
    "    y_test_pred = model.predict(x_test_scaled)\n",
    "    print(\"Train Acurracy Score\", model.score(x_train_scaled,y_train))\n",
    "    print(\"Train MAE Score: \", mean_absolute_error(y_train_pred,y_train))\n",
    "    print('-' * 20)\n",
    "    print(\"Test Acurracy Score\", model.score(x_test_scaled,y_test))\n",
    "    print(\"Test MAE Score: \", mean_absolute_error(y_test_pred,y_test))\n",
    "    print(\"*\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cf31b4",
   "metadata": {},
   "source": [
    "* The models show No significant imporvement imporvement "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a1b652",
   "metadata": {},
   "source": [
    "#### We are going to use polynomial Features with diffrent degree and check if there are any improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "350703d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------   Poly degree No.2  -------------\n",
      "-----------  lr  -------------\n",
      "Train Acurracy Score 0.3 Test Acurracy Score 0.3\n",
      "Train MAE Score:  5.0 Test MAE Score:  5.29\n",
      "************************************************************\n",
      "-----------  knn  -------------\n",
      "Train Acurracy Score 0.46 Test Acurracy Score 0.21\n",
      "Train MAE Score:  4.42 Test MAE Score:  5.7\n",
      "************************************************************\n",
      "-----------  rf  -------------\n",
      "Train Acurracy Score 0.85 Test Acurracy Score 0.24\n",
      "Train MAE Score:  2.18 Test MAE Score:  5.67\n",
      "************************************************************\n",
      "-----------   Poly degree No.3  -------------\n",
      "-----------  lr  -------------\n",
      "Train Acurracy Score 0.33 Test Acurracy Score 0.3\n",
      "Train MAE Score:  4.94 Test MAE Score:  5.33\n",
      "************************************************************\n",
      "-----------  knn  -------------\n",
      "Train Acurracy Score 0.46 Test Acurracy Score 0.2\n",
      "Train MAE Score:  4.42 Test MAE Score:  5.73\n",
      "************************************************************\n",
      "-----------  rf  -------------\n",
      "Train Acurracy Score 0.86 Test Acurracy Score 0.24\n",
      "Train MAE Score:  2.18 Test MAE Score:  5.68\n",
      "************************************************************\n",
      "-----------   Poly degree No.4  -------------\n",
      "-----------  lr  -------------\n",
      "Train Acurracy Score 0.39 Test Acurracy Score 0.06\n",
      "Train MAE Score:  4.83 Test MAE Score:  5.85\n",
      "************************************************************\n",
      "-----------  knn  -------------\n",
      "Train Acurracy Score 0.46 Test Acurracy Score 0.2\n",
      "Train MAE Score:  4.42 Test MAE Score:  5.73\n",
      "************************************************************\n",
      "-----------  rf  -------------\n",
      "Train Acurracy Score 0.85 Test Acurracy Score 0.24\n",
      "Train MAE Score:  2.2 Test MAE Score:  5.66\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "for i in [2,3,4]:\n",
    "    print(\"----------- \", f\" Poly degree No.{i}\", \" -------------\")\n",
    "    poly2 = PolynomialFeatures(degree=i)\n",
    "    x_train_poly = poly2.fit_transform(x_train)\n",
    "    x_test_poly = poly2.transform(x_test)\n",
    "    for name,model in models.items():\n",
    "        print(\"----------- \", name, \" -------------\")\n",
    "        model.fit(x_train_poly,y_train)\n",
    "        y_train_pred = model.predict(x_train_poly)\n",
    "        y_test_pred = model.predict(x_test_poly)\n",
    "        print(\"Train Acurracy Score\", round(model.score(x_train_poly,y_train),2), \"Test Acurracy Score\", round(model.score(x_test_poly,y_test),2))\n",
    "        print(\"Train MAE Score: \", round(mean_absolute_error(y_train_pred,y_train),2),\"Test MAE Score: \", round(mean_absolute_error(y_test_pred,y_test),2))\n",
    "        print(\"*\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756761b5",
   "metadata": {},
   "source": [
    "### Using Princeple Component Analasis after polynomial with different componant numper and check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5efa6921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using n_componests 2,5,8,10 and checking the results.\n",
    "pca=PCA(n_components=5)\n",
    "x_train_pca10 =pca.fit_transform(x_train)\n",
    "x_test_new_pca10 =pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f520eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------  2  -------------\n",
      "-----------  2  -------------\n",
      "-----------  lr  -------------\n",
      "Train Acurracy Score 0.22 Test Acurracy Score 0.23\n",
      "Train MAE Score:  5.4 Test MAE Score:  5.65\n",
      "************************************************************\n",
      "-----------  knn  -------------\n",
      "Train Acurracy Score 0.41 Test Acurracy Score 0.16\n",
      "Train MAE Score:  4.68 Test MAE Score:  6.02\n",
      "************************************************************\n",
      "-----------  rf  -------------\n",
      "Train Acurracy Score 0.84 Test Acurracy Score 0.15\n",
      "Train MAE Score:  2.33 Test MAE Score:  6.11\n",
      "************************************************************\n",
      "-----------  5  -------------\n",
      "-----------  lr  -------------\n",
      "Train Acurracy Score 0.22 Test Acurracy Score 0.23\n",
      "Train MAE Score:  5.4 Test MAE Score:  5.65\n",
      "************************************************************\n",
      "-----------  knn  -------------\n",
      "Train Acurracy Score 0.42 Test Acurracy Score 0.16\n",
      "Train MAE Score:  4.68 Test MAE Score:  6.02\n",
      "************************************************************\n",
      "-----------  rf  -------------\n",
      "Train Acurracy Score 0.84 Test Acurracy Score 0.15\n",
      "Train MAE Score:  2.32 Test MAE Score:  6.11\n",
      "************************************************************\n",
      "-----------  8  -------------\n",
      "-----------  lr  -------------\n",
      "Train Acurracy Score 0.22 Test Acurracy Score 0.23\n",
      "Train MAE Score:  5.4 Test MAE Score:  5.65\n",
      "************************************************************\n",
      "-----------  knn  -------------\n",
      "Train Acurracy Score 0.41 Test Acurracy Score 0.16\n",
      "Train MAE Score:  4.68 Test MAE Score:  6.02\n",
      "************************************************************\n",
      "-----------  rf  -------------\n",
      "Train Acurracy Score 0.84 Test Acurracy Score 0.15\n",
      "Train MAE Score:  2.32 Test MAE Score:  6.13\n",
      "************************************************************\n",
      "-----------  10  -------------\n",
      "-----------  lr  -------------\n",
      "Train Acurracy Score 0.22 Test Acurracy Score 0.23\n",
      "Train MAE Score:  5.4 Test MAE Score:  5.65\n",
      "************************************************************\n",
      "-----------  knn  -------------\n",
      "Train Acurracy Score 0.41 Test Acurracy Score 0.16\n",
      "Train MAE Score:  4.68 Test MAE Score:  6.02\n",
      "************************************************************\n",
      "-----------  rf  -------------\n",
      "Train Acurracy Score 0.84 Test Acurracy Score 0.15\n",
      "Train MAE Score:  2.33 Test MAE Score:  6.09\n",
      "************************************************************\n",
      "-----------  3  -------------\n",
      "-----------  2  -------------\n",
      "-----------  lr  -------------\n",
      "Train Acurracy Score 0.22 Test Acurracy Score 0.23\n",
      "Train MAE Score:  5.4 Test MAE Score:  5.65\n",
      "************************************************************\n",
      "-----------  knn  -------------\n",
      "Train Acurracy Score 0.42 Test Acurracy Score 0.16\n",
      "Train MAE Score:  4.68 Test MAE Score:  6.02\n",
      "************************************************************\n",
      "-----------  rf  -------------\n",
      "Train Acurracy Score 0.84 Test Acurracy Score 0.15\n",
      "Train MAE Score:  2.32 Test MAE Score:  6.1\n",
      "************************************************************\n",
      "-----------  5  -------------\n",
      "-----------  lr  -------------\n",
      "Train Acurracy Score 0.22 Test Acurracy Score 0.23\n",
      "Train MAE Score:  5.4 Test MAE Score:  5.65\n",
      "************************************************************\n",
      "-----------  knn  -------------\n",
      "Train Acurracy Score 0.42 Test Acurracy Score 0.16\n",
      "Train MAE Score:  4.68 Test MAE Score:  6.02\n",
      "************************************************************\n",
      "-----------  rf  -------------\n",
      "Train Acurracy Score 0.84 Test Acurracy Score 0.15\n",
      "Train MAE Score:  2.33 Test MAE Score:  6.11\n",
      "************************************************************\n",
      "-----------  8  -------------\n",
      "-----------  lr  -------------\n",
      "Train Acurracy Score 0.22 Test Acurracy Score 0.23\n",
      "Train MAE Score:  5.4 Test MAE Score:  5.65\n",
      "************************************************************\n",
      "-----------  knn  -------------\n",
      "Train Acurracy Score 0.42 Test Acurracy Score 0.16\n",
      "Train MAE Score:  4.68 Test MAE Score:  6.02\n",
      "************************************************************\n",
      "-----------  rf  -------------\n",
      "Train Acurracy Score 0.84 Test Acurracy Score 0.15\n",
      "Train MAE Score:  2.33 Test MAE Score:  6.09\n",
      "************************************************************\n",
      "-----------  10  -------------\n",
      "-----------  lr  -------------\n",
      "Train Acurracy Score 0.22 Test Acurracy Score 0.23\n",
      "Train MAE Score:  5.4 Test MAE Score:  5.65\n",
      "************************************************************\n",
      "-----------  knn  -------------\n",
      "Train Acurracy Score 0.42 Test Acurracy Score 0.16\n",
      "Train MAE Score:  4.68 Test MAE Score:  6.02\n",
      "************************************************************\n",
      "-----------  rf  -------------\n",
      "Train Acurracy Score 0.84 Test Acurracy Score 0.14\n",
      "Train MAE Score:  2.32 Test MAE Score:  6.13\n",
      "************************************************************\n",
      "-----------  4  -------------\n",
      "-----------  2  -------------\n",
      "-----------  lr  -------------\n",
      "Train Acurracy Score 0.22 Test Acurracy Score 0.23\n",
      "Train MAE Score:  5.4 Test MAE Score:  5.65\n",
      "************************************************************\n",
      "-----------  knn  -------------\n",
      "Train Acurracy Score 0.41 Test Acurracy Score 0.16\n",
      "Train MAE Score:  4.68 Test MAE Score:  6.02\n",
      "************************************************************\n",
      "-----------  rf  -------------\n",
      "Train Acurracy Score 0.84 Test Acurracy Score 0.15\n",
      "Train MAE Score:  2.33 Test MAE Score:  6.11\n",
      "************************************************************\n",
      "-----------  5  -------------\n",
      "-----------  lr  -------------\n",
      "Train Acurracy Score 0.22 Test Acurracy Score 0.23\n",
      "Train MAE Score:  5.4 Test MAE Score:  5.65\n",
      "************************************************************\n",
      "-----------  knn  -------------\n",
      "Train Acurracy Score 0.42 Test Acurracy Score 0.16\n",
      "Train MAE Score:  4.68 Test MAE Score:  6.02\n",
      "************************************************************\n",
      "-----------  rf  -------------\n",
      "Train Acurracy Score 0.84 Test Acurracy Score 0.14\n",
      "Train MAE Score:  2.32 Test MAE Score:  6.13\n",
      "************************************************************\n",
      "-----------  8  -------------\n",
      "-----------  lr  -------------\n",
      "Train Acurracy Score 0.22 Test Acurracy Score 0.23\n",
      "Train MAE Score:  5.4 Test MAE Score:  5.65\n",
      "************************************************************\n",
      "-----------  knn  -------------\n",
      "Train Acurracy Score 0.42 Test Acurracy Score 0.16\n",
      "Train MAE Score:  4.68 Test MAE Score:  6.02\n",
      "************************************************************\n",
      "-----------  rf  -------------\n",
      "Train Acurracy Score 0.84 Test Acurracy Score 0.15\n",
      "Train MAE Score:  2.33 Test MAE Score:  6.11\n",
      "************************************************************\n",
      "-----------  10  -------------\n",
      "-----------  lr  -------------\n",
      "Train Acurracy Score 0.22 Test Acurracy Score 0.23\n",
      "Train MAE Score:  5.4 Test MAE Score:  5.65\n",
      "************************************************************\n",
      "-----------  knn  -------------\n",
      "Train Acurracy Score 0.41 Test Acurracy Score 0.16\n",
      "Train MAE Score:  4.68 Test MAE Score:  6.02\n",
      "************************************************************\n",
      "-----------  rf  -------------\n",
      "Train Acurracy Score 0.84 Test Acurracy Score 0.15\n",
      "Train MAE Score:  2.33 Test MAE Score:  6.11\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "for i in [2,3,4]:\n",
    "    print(\"----------- \", i, \" -------------\")\n",
    "    poly2 = PolynomialFeatures(degree=i)\n",
    "    x_train_poly = poly2.fit_transform(x_train)\n",
    "    x_test_poly = poly2.transform(x_test)\n",
    "    \n",
    "    for n in [2,5,8,10]:\n",
    "        print(\"----------- \", n, \" -------------\")\n",
    "        pca=PCA(n_components=2)\n",
    "        x_train_pca =pca.fit_transform(x_train)\n",
    "        x_test_pca =pca.transform(x_test)\n",
    "        \n",
    "        for name,model in models.items():\n",
    "            print(\"----------- \", name, \" -------------\")\n",
    "            model.fit(x_train_pca,y_train)\n",
    "            y_train_pred = model.predict(x_train_pca)\n",
    "            y_test_pred = model.predict(x_test_pca)\n",
    "            print(\"Train Acurracy Score\", round(model.score(x_train_pca,y_train),2), \"Test Acurracy Score\", round(model.score(x_test_pca,y_test),2))\n",
    "            print(\"Train MAE Score: \", round(mean_absolute_error(y_train_pred,y_train),2),\"Test MAE Score: \", round(mean_absolute_error(y_test_pred,y_test),2))\n",
    "            print(\"*\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d1f75b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to change the target to numerical to string using dictionery and map it to y train & test\n",
    "str_target = {1:'1',2:'2',3:'3',4:'4',5:'5',6:'6',7:'7',8:'8',9:'9',10:'10',11:'11',12:'12',13:'13',14:'14',15:'15',16:'16',17:'17',18:'18',19:'19',20:'20'}\n",
    "y_train = y_train.map(str_target)\n",
    "y_test = y_test.map(str_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7bfaf738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20     115\n",
       "19     120\n",
       "18     149\n",
       "17     166\n",
       "16     201\n",
       "15     227\n",
       "14     276\n",
       "13     315\n",
       "12     348\n",
       "11     394\n",
       "10     470\n",
       "9      565\n",
       "8      721\n",
       "7      911\n",
       "6     1054\n",
       "5     1249\n",
       "4     1503\n",
       "1     1637\n",
       "3     1711\n",
       "2     1812\n",
       "Name: length_of_stay, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad5661df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying three different classification models to compare between them\n",
    "models = {\"lg\": LogisticRegression(),\n",
    "          \"knnc\": KNeighborsClassifier(),\n",
    "          \"rfc\": RandomForestClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee81b693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------  lg  -------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13232\\1647361245.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"----------- \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\" -------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0my_train_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0my_test_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\diaapython\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1512\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m             \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m             \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msolver\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"liblinear\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sag\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"saga\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m         )\n\u001b[0;32m   1516\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\diaapython\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\diaapython\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    977\u001b[0m     )\n\u001b[0;32m    978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 979\u001b[1;33m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\diaapython\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric)\u001b[0m\n\u001b[0;32m    992\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m         \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m         \u001b[0m_ensure_no_complex_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"O\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\diaapython\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"object\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_object_dtype_isnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input contains NaN\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN"
     ]
    }
   ],
   "source": [
    "for name,model in models.items():\n",
    "        print(\"----------- \", name, \" -------------\")\n",
    "        model.fit(x_train_scaled,y_train)\n",
    "        y_train_pred = model.predict(x_train_scaled)\n",
    "        y_test_pred = model.predict(x_test_scaled)\n",
    "        print(\"Train Acurracy Score\", round(model.score(x_train_scaled,y_train),2), \"Test Acurracy Score\", round(model.score(x_test_scaled,y_test),2))\n",
    "        print(\"Train Precision Score: \", round(precision_score(y_train,y_train_pred,average='micro'),2),\"Test Precision Score: \", round(precision_score(y_test,y_test_pred,average='micro'),2))\n",
    "        print(\"Train Recall Score: \", round(recall_score(y_train,y_train_pred,average='micro'),2),\"Test Recall Score: \", round(recall_score(y_test,y_test_pred,average='micro'),2))\n",
    "        print(\"*\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df899567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using random under sampler to maintain inbalance of the target class\n",
    "resampler = RandomUnderSampler(sampling_strategy='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8548797d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_resample,y_train_resample = resampler.fit_resample(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1279fd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_resample.value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1104f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Stander Scaler for x_train_resampled, x_test\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train_resample)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beadd834",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,model in models.items():\n",
    "        print(\"----------- \", name, \" -------------\")\n",
    "        model.fit(x_train_scaled,y_train_resample)\n",
    "        y_train_pred = model.predict(x_train_resample)\n",
    "        y_test_pred = model.predict(x_test_scaled)\n",
    "        print(\"Train Acurracy Score\", round(model.score(x_train_scaled,y_train_resample),2), \"Test Acurracy Score\", round(model.score(x_test_scaled,y_test),2))\n",
    "        print(\"Train Precision Score: \", round(precision_score(y_train_resample,y_train_pred,average='micro'),2),\"Test Precision Score: \", round(precision_score(y_test,y_test_pred,average='micro'),2))\n",
    "        print(\"Train Recall Score: \", round(recall_score(y_train_resample,y_train_pred,average='micro'),2),\"Test Recall Score: \", round(recall_score(y_test,y_test_pred,average='micro'),2))\n",
    "        print(\"*\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bae155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d40ae0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c861183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e084a8e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fe8519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec68a724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c73e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7daae38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae88ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d85a428",
   "metadata": {},
   "source": [
    "### The Models evaluations results above indicate that there is both under fitting and over fitting in the same time which mean we have to go back again to the preprocessing steps and try to deal with that for example by dropping outliers and also try different way of Categorical incoding like binary encoding."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
